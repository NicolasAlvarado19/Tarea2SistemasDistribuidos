"""
GENERADOR DE TR√ÅFICO

Este servicio simula usuarios reales haciendo preguntas al sistema.
Es como un robot que hace de "muchos usuarios" consultando el sistema.

Funcionalidad:
1. Lee preguntas del dataset
2. Las env√≠a al sistema siguiendo diferentes patrones de tr√°fico
3. Simula comportamiento real (algunas preguntas son m√°s populares)
"""

# ============================================================================
# IMPORTACIONES
# ============================================================================

# requests: para hacer peticiones HTTP a los otros servicios
import requests

# time: para controlar el tiempo entre consultas
import time

# numpy: para generar n√∫meros aleatorios con distribuciones
import numpy as np

# pandas: para leer el CSV con las preguntas
import pandas as pd

# Para leer variables de entorno
import os

# Para hacer logs informativos
import logging

# Para manejar argumentos de l√≠nea de comandos
import sys

# ============================================================================
# CONFIGURAR LOGGING
# ============================================================================

# Configurar el sistema de logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Crear el logger
logger = logging.getLogger(__name__)

# ============================================================================
# CLASE GENERADOR DE TR√ÅFICO
# ============================================================================

class GeneradorTrafico:
    """
    Clase que simula tr√°fico de usuarios consultando el sistema.
    """
    
    def __init__(self, distribucion='poisson', tasa=10):
        """
        Inicializa el generador de tr√°fico.
        
        Par√°metros:
            distribucion: tipo de distribuci√≥n ('poisson', 'uniforme', 'rafagas')
            tasa: consultas por minuto
        """
        
        # Guardar configuraci√≥n
        self.distribucion = distribucion
        self.tasa = tasa  # consultas por minuto
        
        # URLs de los servicios
        # En Docker, los nombres de los servicios son sus hostnames
        self.url_almacenamiento = os.getenv('URL_ALMACENAMIENTO', 'http://almacenamiento:8000')
        self.url_cache = os.getenv('URL_CACHE', 'http://cache:8001')
        self.url_puntuacion = os.getenv('URL_PUNTUACION', 'http://puntuacion:8002')
        
        # Cargar el dataset de preguntas
        logger.info("Cargando dataset de preguntas...")
        
        # Leer el CSV con las 10,000 preguntas
        ruta_dataset = '/datos/preguntas_10k.csv'
        self.df_preguntas = pd.read_csv(ruta_dataset)
        
        logger.info(f"Dataset cargado: {len(self.df_preguntas)} preguntas disponibles")
        
        # Estad√≠sticas
        self.consultas_enviadas = 0
        self.consultas_exitosas = 0
        self.consultas_fallidas = 0
        self.cache_hits = 0
        self.cache_misses = 0
    
    
    def obtener_tiempo_entre_llegadas(self):
        """
        Calcula cu√°nto tiempo esperar antes de la siguiente consulta.
        
        Dependiendo de la distribuci√≥n elegida, genera tiempos diferentes:
        - Poisson: llegadas aleatorias (realista)
        - Uniforme: llegadas regulares (cada X segundos)
        - R√°fagas: per√≠odos tranquilos + per√≠odos intensos
        
        Retorna:
            float: segundos a esperar
        """
        
        if self.distribucion == 'poisson':
            # Distribuci√≥n exponencial (proceso de Poisson)
            # Es como simular llegadas aleatorias de usuarios reales
            # Si tasa = 10 consultas/minuto, promedio = 6 segundos entre consultas
            return np.random.exponential(60 / self.tasa)
        
        elif self.distribucion == 'uniforme':
            # Distribuci√≥n uniforme (llegadas regulares)
            # Siempre espera el mismo tiempo
            # Si tasa = 10 consultas/minuto, espera 6 segundos siempre
            return 60 / self.tasa
        
        elif self.distribucion == 'rafagas':
            # Distribuci√≥n con r√°fagas (bursty)
            # 80% del tiempo: tr√°fico lento (el doble de espera)
            # 20% del tiempo: tr√°fico muy r√°pido (muy poca espera)
            # Simula patrones reales: momentos tranquilos + picos de tr√°fico
            
            if np.random.rand() < 0.8:
                # 80% del tiempo: lento
                return np.random.exponential(120 / self.tasa)
            else:
                # 20% del tiempo: muy r√°pido
                return np.random.exponential(10 / self.tasa)
        
        else:
            # Por defecto, usar Poisson
            return np.random.exponential(60 / self.tasa)
    
    
    def seleccionar_pregunta(self):
        """
        Selecciona una pregunta del dataset.
        
        Usa distribuci√≥n Zipf para simular popularidad:
        - Algunas preguntas son MUY populares (se repiten mucho)
        - Otras son menos populares
        
        Esto es realista: en un sistema real, ciertas preguntas
        se hacen mucho m√°s que otras.
        
        Retorna:
            tuple: (pregunta, respuesta_original)
        """
        
        # Distribuci√≥n Zipf para simular popularidad
        # Zipf: pocas cosas son muy populares, muchas cosas son poco populares
        # Ejemplo: en YouTube, pocos videos tienen millones de vistas,
        # muchos videos tienen pocas vistas
        
        # Generar un √≠ndice con Zipf
        # zipf(1.5) genera n√∫meros donde valores peque√±os son m√°s probables
        indice = np.random.zipf(1.5) - 1
        
        # Asegurarse de que el √≠ndice est√© dentro del rango
        indice = min(indice, len(self.df_preguntas) - 1)
        
        # Obtener la fila correspondiente
        fila = self.df_preguntas.iloc[indice]
        
        return fila['pregunta'], fila['mejor_respuesta']
    
    
    def procesar_consulta(self, pregunta, respuesta_original):
        """
        Procesa una consulta completa a trav√©s del pipeline.
        
        Flujo:
        1. Verificar en cach√©
        2. Si est√° ‚Üí actualizar almacenamiento (cache hit)
        3. Si NO est√° ‚Üí procesar con LLM y almacenar (cache miss)
        
        Par√°metros:
            pregunta: texto de la pregunta
            respuesta_original: respuesta de Yahoo! Answers
        
        Retorna:
            bool: True si fue exitosa, False si hubo error
        """
        
        try:
            # ================================================================
            # PASO 1: Verificar si est√° en cach√©
            # ================================================================
            
            logger.info(f"Verificando cach√© para: {pregunta[:50]}...")
            
            respuesta_cache = requests.post(
                f'{self.url_cache}/verificar',
                json={"texto_pregunta": pregunta},
                timeout=10
            )
            
            datos_cache = respuesta_cache.json()
            
            # ================================================================
            # CASO A: CACHE HIT (la pregunta ya est√° en cach√©)
            # ================================================================
            
            if datos_cache.get('encontrado', False):
                logger.info("‚úÖ CACHE HIT - Respuesta encontrada en cach√©")
                
                self.cache_hits += 1
                
                # Actualizar el almacenamiento con el contador
                requests.post(
                    f'{self.url_almacenamiento}/almacenar',
                    json={
                        "texto_pregunta": pregunta,
                        "respuesta_original": respuesta_original
                    },
                    timeout=10
                )
                
                return True
            
            # ================================================================
            # CASO B: CACHE MISS (la pregunta NO est√° en cach√©)
            # ================================================================
            
            else:
                logger.info("‚ùå CACHE MISS - Procesando con LLM...")
                
                self.cache_misses += 1
                
                # Paso 2: Generar respuesta con LLM y calcular similitud
                respuesta_puntuacion = requests.post(
                    f'{self.url_puntuacion}/generar-y-puntuar',
                    json={
                        "pregunta": pregunta,
                        "respuesta_original": respuesta_original
                    },
                    timeout=60  # Timeout m√°s largo porque el LLM puede tardar
                )
                
                datos_puntuacion = respuesta_puntuacion.json()
                
                logger.info(f"üìä Similitud: {datos_puntuacion['puntuacion_similitud']:.3f}")
                
                # Paso 3: Almacenar en cach√©
                requests.post(
                    f'{self.url_cache}/almacenar',
                    json={
                        "texto_pregunta": pregunta,
                        "respuesta_llm": datos_puntuacion['respuesta_llm'],
                        "puntuacion_similitud": datos_puntuacion['puntuacion_similitud']
                    },
                    timeout=10
                )
                
                # Paso 4: Almacenar en base de datos
                requests.post(
                    f'{self.url_almacenamiento}/almacenar',
                    json={
                        "texto_pregunta": pregunta,
                        "respuesta_original": respuesta_original,
                        "respuesta_llm": datos_puntuacion['respuesta_llm'],
                        "puntuacion_similitud": datos_puntuacion['puntuacion_similitud']
                    },
                    timeout=10
                )
                
                return True
        
        except requests.exceptions.Timeout:
            # Error: el servicio tard√≥ mucho en responder
            logger.error("‚è±Ô∏è TIMEOUT - El servicio tard√≥ mucho")
            return False
        
        except requests.exceptions.ConnectionError:
            # Error: no se pudo conectar al servicio
            logger.error("üîå ERROR DE CONEXI√ìN - No se pudo conectar al servicio")
            return False
        
        except Exception as error:
            # Cualquier otro error
            logger.error(f"‚ùå ERROR: {str(error)}")
            return False
    
    
    def ejecutar(self, num_consultas=500, duracion_minutos=None):
        """
        Ejecuta el generador de tr√°fico.
        
        Par√°metros:
            num_consultas: cu√°ntas consultas enviar (default: 500)
            duracion_minutos: l√≠mite de tiempo (opcional)
        """
        
        logger.info("="*80)
        logger.info("üöÄ INICIANDO GENERADOR DE TR√ÅFICO")
        logger.info("="*80)
        logger.info(f"üìä Distribuci√≥n: {self.distribucion}")
        logger.info(f"‚ö° Tasa: {self.tasa} consultas/minuto")
        logger.info(f"üéØ Total consultas: {num_consultas}")
        logger.info("="*80)
        
        # Tiempo de inicio
        tiempo_inicio = time.time()
        
        # Bucle principal
        while self.consultas_enviadas < num_consultas:
            
            # Verificar l√≠mite de tiempo (si se especific√≥)
            if duracion_minutos:
                tiempo_transcurrido = (time.time() - tiempo_inicio) / 60
                if tiempo_transcurrido > duracion_minutos:
                    logger.info(f"‚è±Ô∏è Tiempo l√≠mite alcanzado: {duracion_minutos} minutos")
                    break
            
            # Seleccionar una pregunta
            pregunta, respuesta = self.seleccionar_pregunta()
            
            # Procesar la consulta
            exito = self.procesar_consulta(pregunta, respuesta)
            
            # Actualizar estad√≠sticas
            self.consultas_enviadas += 1
            
            if exito:
                self.consultas_exitosas += 1
            else:
                self.consultas_fallidas += 1
            
            # Mostrar progreso cada 50 consultas
            if self.consultas_enviadas % 50 == 0:
                self.mostrar_progreso()
            
            # Esperar antes de la siguiente consulta
            tiempo_espera = self.obtener_tiempo_entre_llegadas()
            time.sleep(tiempo_espera)
        
        # Mostrar resumen final
        self.mostrar_resumen_final(tiempo_inicio)
    
    
    def mostrar_progreso(self):
        """Muestra el progreso actual"""
        
        logger.info("="*80)
        logger.info(f"üìà PROGRESO: {self.consultas_enviadas} consultas enviadas")
        logger.info(f"‚úÖ Exitosas: {self.consultas_exitosas}")
        logger.info(f"‚ùå Fallidas: {self.consultas_fallidas}")
        logger.info(f"üíæ Cache Hits: {self.cache_hits}")
        logger.info(f"üîç Cache Misses: {self.cache_misses}")
        
        # Calcular tasa de acierto del cach√©
        if self.consultas_enviadas > 0:
            tasa_hit = (self.cache_hits / self.consultas_enviadas) * 100
            logger.info(f"üìä Tasa de acierto del cach√©: {tasa_hit:.1f}%")
        
        logger.info("="*80)
    
    
    def mostrar_resumen_final(self, tiempo_inicio):
        """Muestra el resumen final de la ejecuci√≥n"""
        
        tiempo_total = time.time() - tiempo_inicio
        
        logger.info("")
        logger.info("="*80)
        logger.info("üèÅ GENERACI√ìN DE TR√ÅFICO COMPLETADA")
        logger.info("="*80)
        logger.info(f"‚è±Ô∏è Tiempo total: {tiempo_total:.2f} segundos ({tiempo_total/60:.2f} minutos)")
        logger.info(f"üìä Total consultas: {self.consultas_enviadas}")
        logger.info(f"‚úÖ Exitosas: {self.consultas_exitosas}")
        logger.info(f"‚ùå Fallidas: {self.consultas_fallidas}")
        logger.info(f"üíæ Cache Hits: {self.cache_hits}")
        logger.info(f"üîç Cache Misses: {self.cache_misses}")
        
        if self.consultas_enviadas > 0:
            tasa_exito = (self.consultas_exitosas / self.consultas_enviadas) * 100
            tasa_hit = (self.cache_hits / self.consultas_enviadas) * 100
            throughput = self.consultas_enviadas / tiempo_total
            
            logger.info(f"üìà Tasa de √©xito: {tasa_exito:.1f}%")
            logger.info(f"üìä Tasa de acierto del cach√©: {tasa_hit:.1f}%")
            logger.info(f"‚ö° Throughput: {throughput:.2f} consultas/segundo")
        
        logger.info("="*80)


# ============================================================================
# PUNTO DE ENTRADA
# ============================================================================

if __name__ == "__main__":
    
    # Leer argumentos de l√≠nea de comandos
    distribucion = sys.argv[1] if len(sys.argv) > 1 else 'poisson'
    tasa = int(sys.argv[2]) if len(sys.argv) > 2 else 20
    num_consultas = int(sys.argv[3]) if len(sys.argv) > 3 else 500
    
    # Crear el generador
    generador = GeneradorTrafico(distribucion=distribucion, tasa=tasa)
    
    # Ejecutar
    generador.ejecutar(num_consultas=num_consultas)